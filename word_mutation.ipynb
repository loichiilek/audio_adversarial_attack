{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\chiilek\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\chiilek\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\chiilek\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\chiilek\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\chiilek\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\chiilek\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from deepspeech import Model\n",
    "import wave\n",
    "import numpy as np\n",
    "import soundfile\n",
    "from mutators import *\n",
    "import scipy.io.wavfile\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import deepspeech\n",
    "\n",
    "from tensorflow.python.keras.backend import ctc_label_dense_to_sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using DeepSpeech Model 0.6.0\n",
    "Using soundfile experience.wav \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_word: experience\n"
     ]
    }
   ],
   "source": [
    "# Constants for the deepspeech model\n",
    "\n",
    "MODEL_PATH = \"./deepspeech-0.6.0-models/output_graph.pbmm\"\n",
    "BEAM_WIDTH = 500\n",
    "\n",
    "# Audio Path\n",
    "AUDIO_PATH = \"./audio/experience.wav\"\n",
    "\n",
    "# Load pretained DeepSpeech Model\n",
    "ds = Model(MODEL_PATH, BEAM_WIDTH)\n",
    "\n",
    "# Read soundfile\n",
    "audio_data, sr = soundfile.read(AUDIO_PATH ,dtype='int16')\n",
    "\n",
    "# Deepspeech original interpretation\n",
    "print(\"input_word: \" + ds.stt(audio_data))\n",
    "\n",
    "# Specify tokens used\n",
    "toks = \" abcdefghijklmnopqrstuvwxyz'-\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutation of audio\n",
    "100 generations\n",
    "10 children per generation\n",
    "\n",
    "Cost Function: Edit Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "NUM_GEN = 30\n",
    "NUM_CHILD = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# editDistance function for measuring mutated audio's distance from adversarial target\n",
    "def edit_distance(word1: str, word2: str) -> int:\n",
    "\n",
    "    memo = {}\n",
    "\n",
    "    for i in range(len(word1) + 1):\n",
    "        memo[i] = i\n",
    "\n",
    "    for y in range(1, len(word2) + 1):\n",
    "        curr = {}\n",
    "        curr[0] = y\n",
    "\n",
    "        for x in range(1, len(word1) + 1):\n",
    "            if word1[x-1] == word2[y-1]:\n",
    "                curr[x] = memo[x-1]\n",
    "            else:\n",
    "                curr[x] = min([curr[x-1], memo[x], memo[x-1]]) + 1\n",
    "\n",
    "        memo = curr\n",
    "\n",
    "\n",
    "    return memo[len(word1)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metadata_to_string(metadata):\n",
    "    return ''.join(item.character for item in metadata.items)\n",
    "\n",
    "def words_from_metadata(metadata):\n",
    "    word = \"\"\n",
    "    word_list = []\n",
    "    word_start_time = 0\n",
    "    # Loop through each character\n",
    "    for i in range(0, metadata.num_items):\n",
    "        item = metadata.items[i]\n",
    "        # Append character to word if it's not a space\n",
    "        if item.character != \" \":\n",
    "            word = word + item.character\n",
    "        # Word boundary is either a space or the last character in the array\n",
    "        if item.character == \" \" or i == metadata.num_items - 1:\n",
    "            word_duration = item.start_time - word_start_time\n",
    "\n",
    "            if word_duration < 0:\n",
    "                word_duration = 0\n",
    "\n",
    "            each_word = dict()\n",
    "            each_word[\"word\"] = word\n",
    "            each_word[\"start_time \"] = round(word_start_time, 4)\n",
    "            each_word[\"duration\"] = round(word_duration, 4)\n",
    "\n",
    "            word_list.append(each_word)\n",
    "            # Reset\n",
    "            word = \"\"\n",
    "            word_start_time = 0\n",
    "        else:\n",
    "            if len(word) == 1:\n",
    "                # Log the start time of the new word\n",
    "                word_start_time = item.start_time\n",
    "\n",
    "    return word_list\n",
    "\n",
    "def meta_info(metadata):\n",
    "    word = \"\"\n",
    "\n",
    "    for i in range(0, metadata.num_items):\n",
    "        item = metadata.items[i]\n",
    "        if item.character == \" \" or i == metadata.num_items - 1:\n",
    "            last_word_timestep = int((len(audio_data) / sr - item.start_time) / 0.02)\n",
    "            for j in range(last_word_timestep):\n",
    "                word += item.character\n",
    "            break\n",
    "\n",
    "        for j in range(metadata.items[i+1].timestep - item.timestep):\n",
    "            word += item.character\n",
    "    \n",
    "    return word\n",
    "\n",
    "def metadata_json_output(metadata):\n",
    "    json_result = dict()\n",
    "    json_result[\"words\"] = words_from_metadata(metadata)\n",
    "    json_result[\"confidence\"] = metadata.confidence\n",
    "    return json.dumps(json_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctc_cost(mutated_word, target_word):\n",
    "    mutated_vector = tf.convert_to_tensor([toks.index(char) for char in mutated_word])\n",
    "    target_vector = tf.convert_to_tensor([[toks.index(char) for char in target_word]])\n",
    "    \n",
    "    print(target_vector.shape)\n",
    "    target = ctc_label_dense_to_sparse(target_phrase, target_phrase_lengths)\n",
    "\n",
    "    tensor, neg_log_prob = tf.nn.ctc_loss(labels=tf.cast(target, tf.int32), inputs=logits, sequence_length=lengths)\n",
    "\n",
    "    print(tensor)\n",
    "    print(neg_log_prob)\n",
    "    print(mutated_vector)\n",
    "    print(target_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the the target\n",
    "target_word = \"experiment\"\n",
    "\n",
    "original_word = ds.stt(audio_data)\n",
    "new_audio_data = audio_data\n",
    "new_word = original_word\n",
    "cost = edit_distance(original_word, target_word)\n",
    "\n",
    "# for i in range(NUM_GEN):\n",
    "    \n",
    "#     print(\"=======================\")\n",
    "#     print(\"Generation: \" + str(i + 1))\n",
    "#     print(\"Best Word: \" + new_word)\n",
    "#     print(\"Cost: \" + str(cost))\n",
    "#     print(\"=======================\")\n",
    "#     generation_best_audio = new_audio_data\n",
    "#     gen_word = new_word\n",
    "    \n",
    "#     for i in range(NUM_CHILD):\n",
    "#         child_audio = Mutators.audio_whitenoise(generation_best_audio, 500).astype(np.int16)\n",
    "#         child_metadata = ds.sttWithMetadata(child_audio)\n",
    "#         child_word = metadata_to_string(ds.sttWithMetadata(child_audio))\n",
    "#         child_cost = edit_distance(child_word, target_word)\n",
    "#         print(meta_info(child_metadata))\n",
    "        \n",
    "#         print(\"mutated word: \" + child_word)\n",
    "#         print(\"mutated cost: \" + str(child_cost))\n",
    "#         ctc_cost(meta_info(child_metadata), target_word)\n",
    "#         print(\"===================\")\n",
    "        \n",
    "#         if child_cost < cost:\n",
    "#             generation_best_audio = child_audio\n",
    "#             gen_word = child_word\n",
    "#             cost = child_cost\n",
    "        \n",
    "#     new_word = gen_word\n",
    "#     new_audio_data = generation_best_audio  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Writing as wav file\n",
    "# soundfile.write(\"new_audio\" + \".wav\", new_audio_data, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5, 5, 5, 5, 5, 5, 5, 5, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 16, 16, 16, 5, 18, 18, 18, 9, 5, 5, 5, 14, 3, 5, 5]]\n",
      "[[5, 24, 16, 5, 18, 9, 13, 5, 14, 20]]\n"
     ]
    }
   ],
   "source": [
    "# Example of a single mutation in a one generation\n",
    "#\n",
    "mutated_word_ex = \"eeeeeeeexxxxxxxxxxxxxxxxxxxxxxxxxxxppperrrieeencee\"\n",
    "target_word_ex = \"experiment\"\n",
    "\n",
    "mutated_vector = [[toks.index(char) for char in mutated_word_ex]]\n",
    "target_vector = [[toks.index(char) for char in target_word_ex]]\n",
    "\n",
    "print(mutated_vector)\n",
    "print(target_vector)\n",
    "\n",
    "# tf.nn.ctc_loss(target_vector, mutated_vector, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5 24 16  5 18  9 13  5 14 20]]\n",
      "(1, 10)\n"
     ]
    }
   ],
   "source": [
    "target_phrase = np.array([list(t)+[0]*(10-len(t)) for t in target_vector])\n",
    "print(target_phrase)\n",
    "print(target_phrase.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10)\n"
     ]
    }
   ],
   "source": [
    "target_phrase_length = np.array([len(x) for x in target_vector])\n",
    "print(target_phrase.shape)\n",
    "\n",
    "target  = ctc_label_dense_to_sparse(target_phrase, target_phrase_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.framework.sparse_tensor.SparseTensor at 0x20200ff57b8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = [50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import DeepSpeech\n",
    "from tf_logits import get_logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(1), Dimension(50)])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutated_tensor = tf.convert_to_tensor(mutated_vector)\n",
    "mutated_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size: 1\n",
      "size: 50\n",
      "(1, 562)\n",
      "[0, 10, 20, 30]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'DeepSpeech' has no attribute 'create_flags'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-19a40f397478>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_logits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmutated_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\School\\FYP\\ds_test_env\\tf_logits.py\u001b[0m in \u001b[0;36mget_logits\u001b[1;34m(new_input, length, first)\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[0mfirst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m         \u001b[0mDeepSpeech\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_flags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m         \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malphabet_config_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"DeepSpeech/data/alphabet.txt\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[0mDeepSpeech\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitialize_globals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'DeepSpeech' has no attribute 'create_flags'"
     ]
    }
   ],
   "source": [
    "\n",
    "logits = get_logits(mutated_tensor, tf.convert_to_tensor(lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = tf.random_normal(mutated_tensor.shape,stddev=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:  print(noise.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctcloss = tf.nn.ctc_loss(labels=tf.cast(target, tf.int32), inputs=logits, sequence_length=lengths)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
